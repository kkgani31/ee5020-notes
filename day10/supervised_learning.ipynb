{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b31b79d-d5a8-4f39-9902-bcba719c6052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api\n",
    "import statsmodels.formula.api\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets\n",
    "import sklearn.svm\n",
    "import sklearn.linear_model\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976b15e9-6c4e-43b5-88cf-ecd5a8be02cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Time-series Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c49ee2-db04-4615-9ab6-e2ddfdb20eb0",
   "metadata": {},
   "source": [
    "## Deterministic vs. Stochastic Processes\n",
    "\n",
    "1. **What is a deterministic process?**: Next values depend on previous or known steps\n",
    "2. **What is an example of a deterministic process?**:\n",
    "3. **What is a stochastic process?**: Doesn't depend on previous steps, \"random\"\n",
    "4. **Are most physical phenomena deterministic or stochastic?**: Stochastic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ca8e91-c49c-4d40-b0c7-2d7fb3c668c5",
   "metadata": {},
   "source": [
    "## Time-series patterns\n",
    "\n",
    "1. **Stationarity**: mean and stdev constant over time\n",
    "2. **Trend**: changes in mean over time\n",
    "3. **Seasonality**: Systemic, periodic variation\n",
    "\n",
    "![Air Passenger Data time-series example](air_log_transform.PNG)\n",
    "\n",
    "*Figure 1: Air passenger time-series data and log transform of data.*\n",
    "\n",
    "![Air Passenger Data time-series example](air_log_trend.png) ![Air Passenger Data time-series example](air_log_seasonality.png)\n",
    "\n",
    "*Figure 2: Components for trend (left) of log transform of air data and seasonality (right) of log transform of air data.*\n",
    "\n",
    "\n",
    "![Air Passenger Data time-series example](air_log_residual.png)\n",
    "\n",
    "*Figure 3: Residual component of log transform of air data.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e54398a-c947-4211-b655-afde5f8e2fa3",
   "metadata": {},
   "source": [
    "## Forecasting time-series data\n",
    "\n",
    "Using the log of the data can help with stabilizing standard deviation. Assuming stationarity with linear decomposition techniques:\n",
    "\n",
    "$y_t = m_t + s_t + r_t$ where $y_t$ is the value of the time series, $m_t$ is the trend component, $s_t$ is the seasonality component, and $r_t$ is a residual component.\n",
    "\n",
    "Try using `statsmodels.tsa.seasonal.seasonal_decompose()` with the `https://static-resources.zybooks.com/static/AirPassengers.csv` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73502b3d-6921-4280-8544-4ff3e4d2b6c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b295ffad-b6cf-4a2d-93ee-94ef3e66e4f6",
   "metadata": {},
   "source": [
    "## Error (cost or loss) functions for forecasting\n",
    "\n",
    "- $e(x) = y_{true}(x) - y_{pred}(x)$\n",
    "- **Mean squared error (MSE):** $\\frac{1}{n} \\sum_{i=1}^{n} e_i^2$\n",
    "- **Mean absolute error (MAE):** $\\frac{1}{n} \\sum_{i=1}^{n} |e_i|$\n",
    "- **Mean absolute percentage error (MAPE):** $100\\% \\cdot \\frac{1}{n} \\sum_{i=1}^{n} |\\frac{e_i}{y_i}|$\n",
    "- Even more metrics! See the [scikit-learn documentation](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics) for more.\n",
    "\n",
    "Let's write functions for these using `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a35601-8c4c-4ee6-9665-95c4c14e154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mse(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Returns the mean squared error given y_true and y_pred.\n",
    "    \"\"\"\n",
    "    return np.sum(np.square(y_true-y_pred)) * 1/(y_true.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4908d5-20f7-469d-b165-4ae82a52c257",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227c9773-0c75-4a27-a599-e2caa399b571",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "- **Machine learning:** Generic term for computer algorithms that build models based on sample data\n",
    "- **Task:** What the statistical model does (classification vs. regression vs. clustering)\n",
    "- **Features:** Properties, attributes, or predictors of a dataset\n",
    "- **Supervised learning:** Estimator optimization using known data labels (\"correct\" data)\n",
    "\n",
    "We will be using the [`scikit-learn`](https://scikit-learn.org) library, which is shortened to `sklearn` in code. Go ahead and use `mamba` to install `scikit-learn`.\n",
    "\n",
    "## Choosing the machine learning estimator to use\n",
    "\n",
    "There's a [convenient chart](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) available on scikit-learn's documentation.  There's also a [massive list of all of the types of supervised learning](https://scikit-learn.org/stable/supervised_learning.html) that exists in `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f74be2-1ac9-457a-b4b5-db2dc9b25388",
   "metadata": {},
   "source": [
    "## Trying out some regression on the Diabetes dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3472a7b5-2937-418a-8355-009c57a86914",
   "metadata": {},
   "source": [
    "First, load the Diabetes dataset, using `sklearn.datasets.load_diabetes()` as a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9c112a-bee9-4109-971b-e48d6272417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diabetes = pd.read_csv('https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt',\n",
    "                          sep='\\t')\n",
    "df_diabetes.columns = df_diabetes.columns.str.lower()\n",
    "df_diabetes.head()\n",
    "df_diabetes_data = df_diabetes.drop('y', axis=1)\n",
    "df_diabetes_target = df_diabetes['y'].copy()\n",
    "print(f\"Data:\\n{df_diabetes_data.head()}\")\n",
    "print(f\"Target:\\n{df_diabetes_target.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97549cf7-f57a-469c-b7ef-1d463ff4308c",
   "metadata": {},
   "source": [
    "Sometimes, it's helpful to use a `sns.pairplot` to see how everything behaves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59303b48-6ecf-44f0-9f31-13e9c99302b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df_diabetes, hue='y', kind='scatter', palette='plasma')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9da2772-2dfa-40f9-9fbd-3d18cb428e43",
   "metadata": {},
   "source": [
    "Next, let's just try ordinary least squares (but from `sklearn.linear_model.LinearRegression()`) with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c02147c-d1b2-498a-bc44-6c36bf70d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diabetes_data_subbed = df_diabetes_data[['bmi', 'bp', 's4', 's5', 's6']]\n",
    "\n",
    "regress_diabetes_model = sklearn.linear_model.LinearRegression()\n",
    "regress_diabetes_model.fit(df_diabetes_data_subbed, df_diabetes_target)\n",
    "print(f\"fit score: {regress_diabetes_model.score(df_diabetes_data_subbed, df_diabetes_target)}\")\n",
    "print(f\"coef names: {regress_diabetes_model.feature_names_in_}\")\n",
    "print(f\"coefficients: {regress_diabetes_model.coef_}\")\n",
    "print(f\"intercept: {regress_diabetes_model.intercept_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a6f85e-38ee-4f24-b4e2-deffa377c2da",
   "metadata": {},
   "source": [
    "Now, we can try another model, such as `Ridge`, `Lasso`, or `ElasticNet`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3142303-d81e-4105-95d7-c8048e5eedb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_linear_regressor(model_to_use: object,\n",
    "                          true_features: pd.DataFrame,\n",
    "                          true_targets: pd.Series) -> object:\n",
    "    \"\"\"\n",
    "    Test a linear regressor (assuming models in sklearn.linear_model).\n",
    "    \n",
    "    :param model_to_use: The model to use (e.g. sklearn.linear_model.Ridge)\n",
    "    :param true_feature: The dataframe of features from the dataset\n",
    "    :param true_targets: The series of targets from the dataset\n",
    "    :returns: the trained model\n",
    "    \"\"\"\n",
    "    model = model_to_use()\n",
    "    model.fit(true_features, true_targets)\n",
    "    print(f\"Testing model: {model}\")\n",
    "    print(f\"fit score: {model.score(true_features, true_targets)}\")\n",
    "    print(f\"coef names: {model.feature_names_in_}\")\n",
    "    print(f\"coefficients: {model.coef_}\")\n",
    "    print(f\"intercept: {model.intercept_}\")\n",
    "    return model\n",
    "\n",
    "test_linear_regressor(sklearn.linear_model.Ridge, df_diabetes_data_subbed, df_diabetes_target)\n",
    "test_linear_regressor(sklearn.linear_model.ElasticNet, df_diabetes_data_subbed, df_diabetes_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e5d993-b763-4d2d-a889-47c8b7a42878",
   "metadata": {},
   "source": [
    "Let's try something different -- the Support Vector Machine (SVM), `sklearn.svm.SVR()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004bc3a3-ebc6-4da1-bbca-1f17b42d6c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_diabetes_model = sklearn.svm.SVR(kernel=\"linear\")\n",
    "svm_diabetes_model.fit(df_diabetes_data_subbed, df_diabetes_target)\n",
    "print(f\"fit score: {svm_diabetes_model.score(df_diabetes_data_subbed, df_diabetes_target)}\")\n",
    "print(f\"coef names: {svm_diabetes_model.feature_names_in_}\")\n",
    "print(f\"coefficients: {svm_diabetes_model.coef_}\")\n",
    "print(f\"intercept: {svm_diabetes_model.intercept_}\")\n",
    "print(f\"support vectors: {svm_diabetes_model.support_vectors_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d03d3e2-1347-46e9-9e80-672028c77fd1",
   "metadata": {},
   "source": [
    "## What's the catch?\n",
    "\n",
    "How do we know we are overfitting, underfitting, etc.? --> Validation and Testing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac42424-f3e6-44a8-8733-61f9818732e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm_diabetes_model = sklearn.svm.SVR(kernel=\"linear\")\n",
    "scores = sklearn.model_selection.cross_val_score(svm_diabetes_model, \n",
    "                                                 df_diabetes_data_subbed, \n",
    "                                                 df_diabetes_target, \n",
    "                                                 cv=7)\n",
    "print(f\"Cross-validation scores: {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eedbe8-d884-48ae-993d-98ae882b5a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble\n",
    "\n",
    "rf_diabetes_model = sklearn.ensemble.RandomForestRegressor(n_estimators=1000)\n",
    "scores = sklearn.model_selection.cross_val_score(rf_diabetes_model, \n",
    "                                                 df_diabetes_data, \n",
    "                                                 df_diabetes_target, \n",
    "                                                 cv=7,\n",
    "                                                 verbose=2)\n",
    "print(f\"Cross-validation scores: {scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af05fb59-a4bb-4a8f-9011-87a6dbcfdad7",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de3ece2-695e-4551-b340-cab3224ee74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "\n",
    "feature_selector = SelectKBest(f_regression, k=6)\n",
    "feature_selector.fit_transform(df_diabetes_data, df_diabetes_target)\n",
    "features_info = zip(feature_selector.feature_names_in_, feature_selector.pvalues_, feature_selector.scores_)\n",
    "print(\"f_regression (linear assumption) results:\")\n",
    "for feature_name, p_value, score in features_info:  # TODO: sort\n",
    "    print(f\"{feature_name}: {score} with p-value {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6511e13-3959-4033-a825-d4d06bfcd25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selector = SelectKBest(mutual_info_regression, k=6)\n",
    "feature_selector.fit_transform(df_diabetes_data, df_diabetes_target)\n",
    "features_info = zip(feature_selector.feature_names_in_, feature_selector.scores_)\n",
    "print(\"mutual_info_regression (nonlinear assumption) results:\")\n",
    "for feature_name, score in features_info:\n",
    "    print(f\"{feature_name}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6440d344-fd2b-4968-af02-e41fb94486fa",
   "metadata": {},
   "source": [
    "## Homework 2 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2319754-2800-412b-a8d4-59dc7b59990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "\n",
    "grades = np.array(sorted([5.5, 10, 10, 5.5, 5, 7.75, 4.5, 5.5, 5.5, 10, 9.5, 5.5, 8.25, 10, 9.9, 6.5, 9]))\n",
    "df_grades = pd.Series(grades)\n",
    "df_grades.describe()\n",
    "print(f\"mode 1: {df_grades[df_grades < 7.75].mean()}\")\n",
    "print(f\"mode 2: {df_grades[df_grades >= 7.75].mean()}\")\n",
    "scipy.stats.ttest_ind(df_grades[df_grades < 7.75], df_grades[df_grades >= 7.75])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd701b8d-38a2-46d9-bac9-40497e1851e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_grades, binrange=(0.0, 10.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28ffee2-a6b7-404a-81e0-d3d110e70c4b",
   "metadata": {},
   "source": [
    "### Notes on Homework 2\n",
    "\n",
    "There has a pattern of work sharing, in particular incorrect work, with these two homework assignments.\n",
    "\n",
    "Do not copy and paste other students' work, this is not allowed -- it is considered cheating.  Academic dishonesty results in an automatic failing grade with the course.  I did not give the automatic fail penalty this time.  If cheating is found, the grade will become an automatic zero in the future.  If you have any questions, please feel free to email me.\n",
    "\n",
    "You MUST explain all of the justification for writing the Python code which you use to help you analyze datasets. You may talk through problems with your peers, but you must perform your own writing and coding. If you use other sources to help you, please cite them.\n",
    "\n",
    "If you are having trouble and have questions or would like clarifications on homework problems, please feel free to message me on Teams, Canvas, or email."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a29825e-e62f-441b-90ed-c8c5eadc1294",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Supervised learning steps from scratch\n",
    "\n",
    "Dataset: `ml_datasets/power_plant.csv`\n",
    "\n",
    "References cited:\n",
    "\n",
    "<p style=\"font-size: smaller\">\n",
    "    Pınar Tüfekci, Prediction of full load electrical power output of a base load operated combined cycle power plant using machine learning methods, International Journal of Electrical Power & Energy Systems, Volume 60, September 2014, Pages 126-140, ISSN 0142-0615.\n",
    "</p>\n",
    "<p style=\"font-size: smaller\">\n",
    "    Heysem Kaya, Pınar Tüfekci , Sadık Fikret Gürgen: Local and Global Learning Methods for Predicting Power of a Combined Gas & Steam Turbine, Proceedings of the International Conference on Emerging Trends in Computer and Electronics Engineering ICETCEE 2012, pp. 13-18 (Mar. 2012, Dubai).\n",
    "</p>\n",
    "\n",
    "\n",
    "#### Dataset summary\n",
    "\n",
    "The dataset contains 9568 data points collected from a Combined Cycle Power Plant over 6 years (2006-2011), when the power plant was set to work with full load. Features consist of hourly average ambient variables Temperature (T), Ambient Pressure (AP), Relative Humidity (RH) and Exhaust Vacuum (V) to predict the net hourly electrical energy output (EP) of the plant.\n",
    "\n",
    "A combined cycle power plant (CCPP) is composed of gas turbines (GT), steam turbines (ST) and heat recovery steam generators. In a CCPP, the electricity is generated by gas and steam turbines, which are combined in one cycle, and is transferred from one turbine to another. While the Vacuum is colected from and has effect on the Steam Turbine, he other three of the ambient variables effect the GT performance.\n",
    "\n",
    "#### Dataset attributes:\n",
    "\n",
    "Features consist of hourly average ambient variables:\n",
    "\n",
    "- Ambient Temperature (AT) in the range 1.81°C and 37.11°C,\n",
    "- Ambient Pressure (AP) in the range 992.89-1033.30 milibar,\n",
    "- Relative Humidity (RH) in the range 25.56% to 100.16%\n",
    "- Exhaust Vacuum (V) in the range 25.36-81.56 cm Hg\n",
    "- Net hourly electrical energy output (PE) 420.26-495.76 MW\n",
    "\n",
    "The averages are taken from various sensors located around the plant that record the ambient variables every second. The variables are given without normalization. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a128bd7d-293c-4b94-a2c9-7e306792759d",
   "metadata": {},
   "source": [
    "### Step 1: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2ab9dc-447c-4ff0-93ef-c9ef1ef31fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.pipeline\n",
    "import sklearn.svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc40669-4b31-4f63-ae58-90e9a2f4c1ec",
   "metadata": {},
   "source": [
    "### Step 2: Import and visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b694ab4d-d11b-4712-85a7-4818604f6151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2c3208-dbef-4e9d-8c7a-e7de15c3516b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e039721f-7685-4f04-84b5-540d80c08f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56bff023-018f-4504-97f9-4ce6435a7668",
   "metadata": {},
   "source": [
    "### Step 3: Clean data as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63812812-93c8-4ebb-8307-1cbe56a0698d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa788e25-d4b3-46e0-b27a-8ea22e07fef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61d3471-f810-4d87-9559-b4cb1f7107b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f1603f5-e93b-4d0d-8236-d04d8551ffbd",
   "metadata": {},
   "source": [
    "### Step 4: Separate data and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b710fab-89c3-4d04-8724-2a2459c8c54e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c46b59-0644-4b93-bcc6-794f42c5ab4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f74c67-ef3d-4d45-a98d-aacd722372db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a646284-dcd3-48d5-9838-84281644ead5",
   "metadata": {},
   "source": [
    "### Step 5: Check selection algorithm (linear vs. nonlinear model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705a1100-21b5-4328-97fd-0204acc4db5b",
   "metadata": {},
   "source": [
    "Select best features for use with linear techniques (`f_regression`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe38d60-5e5e-4b38-9bbc-2ee8256e0bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40cf32a6-382e-4df3-be44-2a6523ea245b",
   "metadata": {},
   "source": [
    "Select best features for use with nonlinear techniques (`mutual_info_regression`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e0e859-aee3-44e9-b23f-1e6c34193bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "365e610a-1f3e-4e8b-8632-c088c6690e80",
   "metadata": {},
   "source": [
    "### Step 6: Build Pipeline (scaler and classifier combined) and select model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be02df59-8401-4165-9cf9-95bb90db9115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "import sklearn.linear_model\n",
    "import sklearn.model_selection\n",
    "\n",
    "num_cores = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0c3099-d2dd-4c6d-8591-4932c93140f2",
   "metadata": {},
   "source": [
    "Let's try good ol' ElasticNet linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e9a109-6cad-4bf1-9a0c-b093df0d0e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e227276-bf74-414b-9990-6662facbaa87",
   "metadata": {},
   "source": [
    "Let's try this dataset with a linear SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842c4acb-d9db-452f-a5e0-47c9b918851a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ff83ae1-692c-4211-aef6-fd4e19551676",
   "metadata": {},
   "source": [
    "Now, try it with a nonlinear SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c4d505-a163-49d8-afe5-af4895477696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9279d825-7ff3-4048-80a5-44fe1a04b678",
   "metadata": {},
   "source": [
    "Let's try a neural network!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02f3333-1284-490f-84c6-8afb59ace24d",
   "metadata": {},
   "source": [
    "### Step 7: Train final model on single shuffled train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948b1c4a-4b0d-4f3b-8806-c8c9854e4094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc-autonumbering": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
