import numpy as np
import scipy.stats
import pandas as pd
from typing import Tuple


def get_confidence_interval(dataset: pd.Series, ci_level: float = 0.95, force_t: bool = False) -> Tuple[float, float]:
    """
    Returns the confidence interval for the given data series, based on the 
      z-distribution if the number of samples > 30 and the t-distribution if
      the number of samples is less than or equal to 30.

    :param dataset: a single series of data to get the confidence interval for the mean.
    :param ci_level: level for the confidence interval
    :param force_t: True if forced to use t distribution
    """
    n = len(dataset)
    mean = dataset.mean()
    stdev = dataset.std()
    stderr = stdev / np.sqrt(n)
    if n > 30 and not force_t:
        return scipy.stats.norm.interval(ci_level, mean, stderr)
    else:
        ddof = n - 1
        return scipy.stats.t.interval(ci_level, ddof, mean, stderr)


df_exam = pd.read_csv('../as_datasets/ExamScores.csv')

df_exam_cis = df_exam.apply(get_confidence_interval, axis=0)  # axis=0 for columns
print(df_exam_cis)
print(df_exam_cis.mean())


# H0 is mu == 86
# HA is mu != 86

print(f"The mean of Exam2 is: {df_exam['Exam2'].mean()}")
print(f"The 95% confidence interval for Exam2 is: {get_confidence_interval(force_t=True, dataset=df_exam['Exam2'])}")
scipy.stats.ttest_1samp(df_exam['Exam2'], 86.0)


df_memory = pd.read_csv('http://data-analytics.zybooks.com/Memory.csv')
# df_memory.head()
print(f"The means are: {df_memory.mean()}")
print(f"The 95% confidence interval for nodrug is: {get_confidence_interval(force_t=True, dataset=df_memory['nodrug'])}")
print(f"The 95% confidence interval for drug is: {get_confidence_interval(force_t=True, dataset=df_memory['drug'])}")
scipy.stats.ttest_ind(df_memory['nodrug'], df_memory['drug'])


print(f"The means are: {df_exam.mean()}")
print(f"The 95% confidence interval for Exam1 is: {get_confidence_interval(force_t=True, dataset=df_exam['Exam1'])}")
print(f"The 95% confidence interval for Exam2 is: {get_confidence_interval(force_t=True, dataset=df_exam['Exam2'])}")
scipy.stats.ttest_rel(df_exam['Exam1'], df_exam['Exam2'])


scipy.stats.f_oneway(df_exam['Exam1'], df_exam['Exam2'], df_exam['Exam3'], df_exam['Exam4'])


# import statsmodels.api as sm
# import statsmodels.formula.api


df_exam.head()

print(df_exam.columns)

# List comprehension
print([col_label for col_label in df_exam.columns])

# list comprehension with filtering
print([col_label for col_label in df_exam.columns if col_label.startswith('Exam')])

# full-form of creating a list of items
list_of_columns = []
for col_label in df_exam.columns:
    if col_label.startswith('Exam'):
        list_of_columns.append(col_label)
print(list_of_columns)


"""
Write a list comprehension that generates all integers from -10 to 10 divisible by 3.

Your result should be: [-9, -6, -3, 0, 3, 6, 9]
"""

list_div_3 = [num for num in np.arange(-10.0, 11.0) if num % 3 == 0]
print(list_div_3)


# First, we need to get a "long-form grouped" version of df_exam:
df_exam["Student_ID"] = df_exam.index + 3000000  # NOTE: normally your dataset would have a unique identifier for each sample of data
df_exam_long = df_exam.melt(id_vars=["Student_ID"],
                            value_vars=[col_label for col_label in df_exam.columns if col_label.startswith('Exam')],
                            var_name="Exam_ID",
                            value_name="Score")
df_exam_long.head()


from statsmodels.stats.multicomp import pairwise_tukeyhsd

exam_hsd = pairwise_tukeyhsd(endog=df_exam_long['Score'], groups=df_exam_long["Exam_ID"])

exam_hsd.summary()






