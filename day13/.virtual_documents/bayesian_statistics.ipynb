import pandas as pd
import numpy as np
import matplotlib.pyplot as plt


df_cookies = pd.DataFrame(index=['B1', 'B2'])


from fractions import Fraction

df_cookies['prior'] = Fraction(1, 2), Fraction(1, 2)  # assumption for bowls
df_cookies


df_cookies['likelihood'] = Fraction(30, 40), Fraction(20, 40)
df_cookies


df_cookies['unnorm_post'] = df_cookies['prior'] * df_cookies['likelihood']
df_cookies


df_cookies['posterior'] = df_cookies['unnorm_post'] / df_cookies['unnorm_post'].sum()
df_cookies


df_monty = pd.DataFrame(index=['D1', 'D2', 'D3'])
df_monty['priors'] = Fraction(1, 3)
df_monty


df_monty['likelihoods'] = Fraction(1, 2), 1, 0
df_monty


df_monty['unnorm_posts'] = df_monty['priors'] * df_monty['likelihoods']
df_monty['posteriors'] = df_monty['unnorm_posts'] / df_monty['unnorm_posts'].sum()
df_monty


import scipy.stats

# modeling bananas in a bunch: 2 to 8 bananas, uniformly possible
example_dist = scipy.stats.randint(2, 9)

x = np.arange(0, 10)
fig = plt.figure(figsize=(8,8))
plt.stem(x, example_dist.pmf(x), label='pmf')
plt.plot(x, example_dist.cdf(x), label='cdf')
plt.grid(linestyle='--')
plt.legend(fontsize='xx-large')


hypotheses = np.arange(1, 11)

prior_dist = scipy.stats.randint(4, 11)
priors = prior_dist.pmf(hypotheses)

print(f"hypotheses: {hypotheses}")
print(f"priors: {priors}")

plt.stem(hypotheses, priors)
plt.title("Prior")


# N = hypotheses
day2_likelihoods = (1 / hypotheses)  # day 2 update
# print(f"day 2 likelihoods: {day2_likelihoods}")


day2_unnorm_posts = priors * day2_likelihoods
# print(f"day 2 unnormalized posteriors: {day2_unnorm_posts}")


day2_posteriors = day2_unnorm_posts / day2_unnorm_posts.sum()
print(f"day 2 posteriors: {day2_posteriors}")
plt.scatter(hypotheses, priors, label="Original priors")
plt.scatter(hypotheses, day2_posteriors, label="Day 2 posteriors")
plt.legend()


day3_priors = day2_posteriors.copy()
day3_likelihoods = (hypotheses - 1) / hypotheses
day3_unnorm_posts = day3_priors * day3_likelihoods
# print(f"day 3 unnormalized posteriors: {day3_unnorm_posts}")

day3_posteriors = day3_unnorm_posts / day3_unnorm_posts.sum()
print(f"day 3 posteriors: {day3_posteriors}")
fig = plt.figure(figsize=(10, 10))
plt.scatter(hypotheses, priors, label="Original priors")
plt.scatter(hypotheses, day2_posteriors, label="Day 2 posteriors")
plt.scatter(hypotheses, day3_posteriors, label="Day 3 posteriors")
plt.legend()


class BayesianEstimation(object):
    def __init__(self, hypotheses: np.ndarray, prior_dist: scipy.stats.rv_discrete):
        """
        BayesianEstimation(hypotheses, prior_dist) builds a Bayesian estimation
          data structure that helps with computing Bayesian estimation problems.

        :param hypotheses: numpy array representing the hypotheses
        :param prior_dist: distribution for the priors
        """
        self.hypotheses = hypotheses
        self.prior_dist = prior_dist
        self.priors = self.prior_dist.pmf(self.hypotheses)
        self.posteriors = [self.priors]

    def update(self, likelihood: np.ndarray) -> np.ndarray:
        """
        update(likelihood) updates the posteriors and returns the normalized posterior
        """
        self.posteriors.append(self.posteriors[-1] * likelihood)
        self.posteriors[-1] = self.posteriors[-1] / self.posteriors[-1].sum()
        return self.posteriors[-1]

    def plot(self):
        """
        plot() plots all the posteriors
        """
        fig = plt.figure(figsize=(10, 10))
        plt.scatter(hypotheses, priors, label="Priors")
        # for idx in range(len(self.posteriors)):
        #     self.posteriors[idx]
        for idx, item in enumerate(self.posteriors):
            plt.plot(hypotheses, item, label=f"Posterior {idx}")
        plt.legend()


hypotheses = np.arange(1, 11)
prior_dist = scipy.stats.randint(4, 11)

my_rabbit_problem = BayesianEstimation(hypotheses, prior_dist)
my_rabbit_problem.update(1 / my_rabbit_problem.hypotheses)
my_rabbit_problem.update((my_rabbit_problem.hypotheses - 1) / my_rabbit_problem.hypotheses)
my_rabbit_problem.plot()


def get_quantile(df_posterior: pd.DataFrame, col_probs: str,
                 col_hypos: str, desired_prob: float) -> float:
    """
    Compute the quantile for the desired probability.
    """
    acc_probs = 0.0
    for _, row in df_posterior.iterrows():
        acc_probs += row[col_probs]
        if acc_probs >= desired_prob:
            return row[col_hypos]
    return np.nan


dict_rabbits = {
    "number of rabbits": my_rabbit_problem.hypotheses,
    "probabilities": my_rabbit_problem.posteriors[-1]
}

df_rabbits = pd.DataFrame.from_dict(dict_rabbits)
df_rabbits.head()


get_quantile(df_rabbits, "probabilities", "number of rabbits", 0.05)


get_quantile(df_rabbits, "probabilities", "number of rabbits", 0.95)


df_rabbits.loc[df_rabbits['probabilities'].idxmax()]


import pandas as pd

df_snowfall = pd.read_csv("https://github.com/AllenDowney/ThinkBayes2/raw/master/data/2239075.csv")
columns_to_keep = ['DATE', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'TMIN']
# df_snowfall = df_snowfall.drop(columns=[col for df_snowfall.columns if col not in columns_to_keep], axis=1)
df_snowfall = df_snowfall[columns_to_keep].copy()  # copy to make it a brand new dataframe
print(len(df_snowfall))
df_snowfall.tail()

def get_year(date_string: str) -> int:
    return int(date_string[0:4])

def get_month(date_string: str) -> int:
    return int(date_string[5:7])

def get_day(date_string: str) -> int:
    return int(date_string[8:])

# fix the date column into separate YEAR, MONTH, DAY columns
df_snowfall['YEAR'] = df_snowfall['DATE'].apply(get_year)
df_snowfall['MONTH'] = df_snowfall['DATE'].apply(get_month)
df_snowfall['DAY'] = df_snowfall['DATE'].apply(get_day)
df_snowfall = df_snowfall.drop(columns=['DATE'], axis=1)

df_snowfall = df_snowfall.dropna()

df_snowfall.head()


import seaborn as sns

sns.pairplot(df_snowfall)


import theano

print(theano.config.cxx)


import numpy as np
import pymc3
import matplotlib.pyplot as plt
import arviz

df_trace = None  # memory placeholder
trace = None # memory placeholder

with pymc3.Model() as snowfall_model:  # context manager in Python
    likelihood_family = pymc3.glm.families.Normal()
    pymc3.GLM.from_formula(formula="SNOW ~ 1 + MONTH + np.power(MONTH, 2)", 
                           data=df_snowfall, family=likelihood_family)
    trace = pymc3.sample(init="adapt_diag", random_seed=42, 
                         return_inferencedata=True)
    print("this still has access to the model")
    df_trace = arviz.summary(trace)
    arviz.plot_trace(trace, figsize=(10, 10), legend=True)

print("hello this no longer has access to the model")


df_trace


plt.figure(figsize=(7, 7))
plt.scatter(df_snowfall["MONTH"], df_snowfall["SNOW"], label="data", alpha=0.02)

y_model = df_trace["mean"]["np.power(MONTH, 2)"] * np.power(df_snowfall["MONTH"], 2) 
y_model += df_trace["mean"]["MONTH"] * df_snowfall["MONTH"] 
y_model += df_trace["mean"]["Intercept"]
plt.scatter(df_snowfall["MONTH"], y_model, label="prediction")

plt.title("Posterior predictive regression lines")
plt.legend()


import bambi as bmb

lin_model = bmb.Model("SNOW ~ np.power(MONTH, 2) + MONTH + 1", data=df_snowfall)
lin_model_fit = lin_model.fit(tune=2000, draws=2000, init="adapt_diag", 
                              pickle_backend="dill", cores=1)


lin_model.plot_priors()


lin_model


arviz.plot_trace(lin_model_fit, legend=True)


df_lin_model_fit = arviz.summary(lin_model_fit)
df_lin_model_fit


plt.figure(figsize=(7, 5))
plt.plot(df_snowfall["MONTH"], df_snowfall["SNOW"], "x", label="data", alpha=0.1)
x_range = np.linspace(df_snowfall["MONTH"].min(), df_snowfall["MONTH"].max(), 2000)
y_pred = df_lin_model_fit["mean"]["Intercept"]
y_pred += df_lin_model_fit["mean"]["np.power(MONTH, 2)"] * (np.power(x_range, 2))
y_pred += df_lin_model_fit["mean"]["MONTH"] * x_range
plt.plot(x_range, y_pred, label="Recovered regression line")
plt.legend()








import bambi as bmb

rob_model = bmb.Model("SNOW ~ np.power(MONTH, 2) + MONTH + 1", data=df_snowfall,
                      family="t")
rob_model_fit = rob_model.fit(tune=2000, draws=2000, init="advi",
                              pickle_backend="dill", cores=1)





















